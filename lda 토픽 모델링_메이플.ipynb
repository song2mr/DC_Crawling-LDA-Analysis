{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9dcd98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1730,
     "status": "ok",
     "timestamp": 1695698150071,
     "user": {
      "displayName": "송찬영",
      "userId": "11858963673253854556"
     },
     "user_tz": -540
    },
    "id": "6b9dcd98",
    "outputId": "0d90f3bb-3368-496c-9216-688accd865ce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import pyLDAvis.gensim_models\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4291dd9",
   "metadata": {
    "id": "d4291dd9"
   },
   "source": [
    "### LDA 참고: https://wikidocs.net/30708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9e4458",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "error",
     "timestamp": 1695699322240,
     "user": {
      "displayName": "송찬영",
      "userId": "11858963673253854556"
     },
     "user_tz": -540
    },
    "id": "2d9e4458",
    "outputId": "d565bca5-9246-4e04-8bca-e44df2ea1734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 817632 entries, 0 to 817631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   817632 non-null  object\n",
      " 1   date    817632 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('maple_title_완.csv',encoding='utf-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7652bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 771201 entries, 0 to 771200\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   771201 non-null  object\n",
      " 1   date    771201 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#광고, 설문 데이터 제거\n",
    "values_to_remove = list(df['title'][0:3])\n",
    "values_to_remove.append('클럽 가면 내 집처럼 잘 놀 것 같은 스타는?')\n",
    "df = df[~df['title'].isin(values_to_remove)]\n",
    "# index 초기화\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a065cbb8",
   "metadata": {
    "id": "a065cbb8"
   },
   "outputs": [],
   "source": [
    "def remove_non(text):\n",
    "    # 정규 표현식을 사용하여 한글, 숫자, 알파벳과 띄어쓰기만 남김\n",
    "    pattern = r'[^\\w가-힣\\s]+'  # 한글, 숫자, 알파벳, 띄어쓰기를 제외한 모든 문자 제거\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7e832d",
   "metadata": {
    "id": "7c7e832d"
   },
   "outputs": [],
   "source": [
    "df['clean_doc'] = df['title'].apply(remove_non)\n",
    "# 길이가 1이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n",
    "# # 전체 단어에 대한 소문자 변환\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: x.lower())\n",
    "#숫자제거\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: re.sub(r'\\d', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a386921",
   "metadata": {
    "id": "9a386921"
   },
   "outputs": [],
   "source": [
    "#불용어 출처:https://mr-doosun.tistory.com/24\n",
    "stop_words = ['app','던파','이것은','순서','메이플','이유','있음','성','퍼','ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ','다들','뭐냐','뭐임','ㅅㅂ','이제','ㅈㄴ','개','억','차','요즘','너무','님들','아님','같은','가면','오늘','게임','ㄹㅇ','ㅋㅋㅋ','ㅋㅋㅋㅋ','ㅋㅋㅋㅋㅋ','지금','근데','존나','아니','씨발','ㅋㅋ','그냥','카드맆','ㅇㅇ','이미지','dc','official','on','on2','on3','on4','on5','on6','아', '휴', '아이구', '아이쿠', '아이고', '어', '나', '우리','있었어요','있었다','있습니다' '저희', '따라', '의해', '을', '를', '에', '의', '가', '으로', '로', '에게', '뿐이다', '의거하여', '근거하여', '입각하여', '기준으로', '예하면', '예를', '들면', '예를', '들자면', '저', '소인', '소생', '저희', '지말고', '하지마', '하지마라', '다른', '물론', '또한', '그리고', '비길수', '없다', '해서는', '안된다', '뿐만', '아니라', '만이', '아니다', '만은', '아니다', '막론하고', '관계없이', '그치지', '않다', '그러나', '그런데', '하지만', '든간에', '논하지', '않다', '따지지', '않다', '설사', '비록', '더라도', '아니면', '만', '못하다', '하는', '편이', '낫다', '불문하고', '향하여', '향해서', '향하다', '쪽으로', '틈타', '이용하여', '타다', '오르다', '제외하고', '이', '외에', '이', '밖에', '하여야', '비로소', '한다면', '몰라도', '외에도', '이곳', '여기', '부터', '기점으로', '따라서', '할', '생각이다', '하려고하다', '이리하여', '그리하여', '그렇게', '함으로써', '하지만', '일때', '할때', '앞에서', '중에서', '보는', '데서', '으로써', '로써', '까지', '해야한다', '일것이다', '반드시', '할줄알다', '할수있다', '할수있어', '임에', '틀림없다', '한다면', '등', '등등', '제', '겨우', '단지', '다만', '할뿐', '딩동', '댕그', '대해서', '대하여', '대하면', '훨씬', '얼마나', '얼마만큼', '얼마큼', '남짓', '여', '얼마간', '약간', '다소', '좀', '조금', '다수', '몇', '얼마', '지만', '하물며', '또한', '그러나', '그렇지만', '하지만', '이외에도', '대해', '말하자면', '뿐이다', '다음에', '반대로', '반대로', '말하자면', '이와', '반대로', '바꾸어서', '말하면', '바꾸어서', '한다면', '만약', '그렇지않으면', '까악', '툭', '딱', '삐걱거리다', '보드득', '비걱거리다', '꽈당', '응당', '해야한다', '에', '가서', '각', '각각', '여러분', '각종', '각자', '제각기', '하도록하다', '와', '과', '그러므로', '그래서', '고로', '한', '까닭에', '하기', '때문에', '거니와', '이지만', '대하여', '관하여', '관한', '과연', '실로', '아니나다를가', '생각한대로', '진짜로', '한적이있다', '하곤하였다', '하', '하하', '허허', '아하', '거바', '와', '오', '왜', '어째서', '무엇때문에', '어찌', '하겠는가', '무슨', '어디', '어느곳', '더군다나', '하물며', '더욱이는', '어느때', '언제', '야', '이봐', '어이', '여보시오', '흐흐', '흥', '휴', '헉헉', '헐떡헐떡', '영차', '여차', '어기여차', '끙끙', '아야', '앗', '아야', '콸콸', '졸졸', '좍좍', '뚝뚝', '주룩주룩', '솨', '우르르', '그래도', '또', '그리고', '바꾸어말하면', '바꾸어서', '말하면', '바꾸어서', '한다면', '만약', '그렇지않으면', '까악', '툭', '딱', '삐걱거리다', '보드득', '비걱거리다', '꽈당', '응당', '해야한다', '에', '가서', '각', '각각', '여러분', '각종', '각자', '제각기', '하도록하다', '와', '과', '그러므로', '그래서', '고로', '한', '까닭에', '하기', '때문에', '거니와', '이지만', '대하여', '관하여', '관한', '과연', '실로', '아니나다를가', '생각한대로', '진짜로', '한적이있다', '하곤하였다', '하', '하하', '허허', '아하', '거바', '와', '오', '왜', '어째서', '무엇때문에', '어찌', '하겠는가', '무슨', '어디', '어느', '로써', '까지', '예하면', '했어요', '해요', '함께', '같이', '더불어', '마저', '마저도', '양자', '모두', '습니다', '가까스로', '하려고하다', '즈음하여', '다른', '다른', '방면으로', '해봐요', '습니까', '했어요', '말할것도', '없고', '무릎쓰고', '개의치않고', '하는것만', '못하다', '하는것이', '낫다', '매', '매번', '들', '모', '어느것', '어느', '로써', '갖고말하자면', '어디', '어느쪽', '어느것', '어느해', '어느', '년도', '라', '해도', '언젠가', '어떤것', '어느것', '저기', '저쪽', '저것', '그때', '그럼', '그러면', '요만한걸', '그래', '그때', '저것만큼', '그저', '이르기까지', '할', '지', '않는다면', '만약', '만일', '위에서', '서술한바와같이', '인', '듯하다', '하', '하지', '않는다면', '만약에', '무엇', '무슨', '어느', '어떤', '내', '내', '경우', '명', '생각', '시간', '그녀', '다시', '이런', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '놓', '이거','진짜','시발']\n",
    "#토큰화\n",
    "tokenized_doc = df['clean_doc'].apply(lambda x: x.split())\n",
    "#불용어 제거\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0393d8f0",
   "metadata": {
    "id": "0393d8f0",
    "outputId": "0001e6c7-b30c-4137-d47b-a9a1856cfbbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              그래서그냥메이플템싹정리한거지\n",
       "1                                섀도어 분쇄닼사 병신같네\n",
       "2                                    춘자 왜케 비호지\n",
       "3                                           쓔발\n",
       "4                                      턴테이블 만원\n",
       "                          ...                 \n",
       "771196    뉴비들한테 제일 진입장벽은 드메템인데 대여시스템이라도 만들어야할듯\n",
       "771197                               물개새끼 안받앗다\n",
       "771198                메린이인데 엠블렘 윗잠 주스탯 퍼뜨면 쓸만함\n",
       "771199                            그래서패치 보통몇시에함\n",
       "771200                             만원 남앗다 진짜뜨나\n",
       "Name: clean_doc, Length: 771201, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불용어 제거를 위해 토큰화 작업을 수행하였지만, TfidfVectorizer(TF-IDF 실습 참고)는\n",
    "#기본적으로 토큰화가 되어있지 않은 텍스트 데이터를 입력으로 사용합니다.\n",
    "#그렇기 때문에 TfidfVectorizer를 사용해서 TF-IDF 행렬을 만들기 위해서\n",
    "#다시 토큰화 작업을 역으로 취소하는 작업을 수행해보도록 하겠습니다. 이를 역토큰화(Detokenization)라고 합니다.\n",
    "detokenized_doc = []\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    \n",
    "    detokenized_doc.append(t)\n",
    "    \n",
    "\n",
    "df['clean_doc'] = detokenized_doc\n",
    "df['clean_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8eeafdc",
   "metadata": {
    "id": "f8eeafdc",
    "outputId": "fe766293-a2b6-4949-cf06-bcc442f3ce9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬의 크기 : (771201, 705486)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',max_df = 0.5, smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(df['clean_doc'])\n",
    "\n",
    "# TF-IDF 행렬의 크기 확인\n",
    "print('TF-IDF 행렬의 크기 :',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ef438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽 개수\n",
    "topic_num =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67622019",
   "metadata": {
    "id": "67622019",
    "outputId": "2495670f-8116-4260-dc66-4fc925b23737",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_components : n개의 토픽을 가졌다고 가정\n",
    "svd_model = TruncatedSVD(n_components=topic_num, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdf9013",
   "metadata": {
    "id": "dbdf9013",
    "outputId": "f670b154-3f12-4fc5-d335-2234064d7df2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 705486)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7652c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('매크로', 0.70925), ('자동사냥', 0.70451), ('사냥', 0.01248), ('mshxxmxx', 0.01213), ('텔레그램', 0.01204), ('판매', 0.01115), ('채집', 0.00264), ('아르테일', 0.00212), ('큐브', 0.00187), ('농장', 0.00154)]\n",
      "Topic 2: [('리부트', 0.97894), ('너프', 0.09141), ('본섭', 0.06609), ('최종뎀', 0.06505), ('ㄴ라고', 0.05653), ('vs', 0.04218), ('닉네임', 0.03974), ('생제', 0.03715), ('메린이', 0.03314), ('뉴비', 0.03097)]\n",
      "Topic 3: [('닉네임', 0.91743), ('메린이', 0.20957), ('뉴비', 0.14546), ('질문', 0.12482), ('어떰', 0.12223), ('많관부', 0.08157), ('ㅁㅌㅊ', 0.07636), ('만원', 0.06508), ('팝니다', 0.06503), ('팔리냐', 0.05255)]\n",
      "Topic 4: [('메린이', 0.71716), ('질문', 0.40212), ('뉴비', 0.38532), ('질문좀', 0.16515), ('유니온', 0.07765), ('vs', 0.07546), ('ㅁㅌㅊ', 0.04749), ('버닝섭', 0.0466), ('무기', 0.04112), ('어떰', 0.04089)]\n",
      "Topic 5: [('뉴비', 0.73497), ('어떰', 0.39405), ('vs', 0.15805), ('코디', 0.04416), ('유니온', 0.03972), ('버닝섭', 0.03528), ('ㅁㅌㅊ', 0.03378), ('추천좀', 0.03305), ('사냥', 0.02786), ('뭐가', 0.02301)]\n",
      "Topic 6: [('어떰', 0.89655), ('메린이', 0.1561), ('코디', 0.07668), ('사냥', 0.02081), ('가격', 0.02039), ('억에', 0.01541), ('스카니아', 0.01385), ('억인데', 0.01162), ('보조', 0.01137), ('무기', 0.01093)]\n",
      "Topic 7: [('vs', 0.9394), ('뭐가', 0.11284), ('추천좀', 0.06387), ('누가', 0.05871), ('불독', 0.05677), ('좋음', 0.04943), ('아케인', 0.04693), ('팡이', 0.04446), ('나로', 0.0425), ('윈브', 0.03995)]\n",
      "Topic 8: [('ㅁㅌㅊ', 0.89666), ('코디', 0.37397), ('본인', 0.09867), ('메붕이', 0.07836), ('평가좀', 0.06229), ('지듣노', 0.06142), ('억에', 0.04045), ('만원', 0.0383), ('조각', 0.03729), ('평가', 0.03578)]\n",
      "Topic 9: [('조각', 0.94447), ('가격', 0.12993), ('스카니아', 0.08823), ('에르다', 0.08676), ('솔에르다', 0.08487), ('루나', 0.07767), ('크로아', 0.07565), ('얼마임', 0.07358), ('만원', 0.06), ('재획', 0.05935)]\n",
      "Topic 10: [('이벤트', 0.63148), ('대리', 0.47869), ('피시방', 0.44696), ('pc방', 0.37579), ('만원', 0.06656), ('피케인', 0.06409), ('모집바로시작', 0.04372), ('피방', 0.0356), ('모집합니다', 0.03412), ('시간당원', 0.03356)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out() # 단어 집합.\n",
    "\n",
    "def get_topics(components, feature_names, n=topic_num):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(svd_model.components_,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efcac2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc.split() for doc in df['clean_doc']]\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc1f24",
   "metadata": {
    "id": "cecc1f24"
   },
   "source": [
    "## 2) LDA 모델 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e918e",
   "metadata": {
    "id": "d33e918e",
    "outputId": "20ce0b19-abc0-48d0-f6c7-30912efd8e94",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5 # 5개의 토픽, k=5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810b5ab",
   "metadata": {
    "id": "5810b5ab",
    "outputId": "0455bfbc-ff0d-4345-ab4d-e31e38f39a7a"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2cad9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
